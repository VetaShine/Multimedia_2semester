# Multimedia_2semester

**Студент: Минеева Светлана Алексеевна**

**Группа: М8О-410Б-21**

## Выводы по лабораторной работе №6

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

| Модель                      | Accuracy | F1     | Precision | Recall | 
|:---------------------------:|:--------:|:------:|:---------:|:------:|
| VGG16 (before)              | 0.6833   | 0.6827 | 0.688     | 0.6833 |
| VGG16 (after)               | 0.8293   | 0.8297 | 0.8308    | 0.8293 |
| ViT-B/16 (before)           | 0.242    | 0.2283 | 0.2405    | 0.242  |
| ViT-B/16 (after)            | 0.8233   | 0.8234 | 0.8267    | 0.8233 |
| Custom CNN (before)         | 0.6153   | 0.6139 | 0.6168    | 0.6153 |
| Custom CNN (after)          | 0.6233   | 0.6209 | 0.6239    | 0.6233 |
| Custom Transformer (before) | 0.436    | 0.4324 | 0.4524    | 0.436  |
| Custom Transformer (after)  | 0.6267   | 0.6222 | 0.6245    |	0.6267 |

После анализа представленных результатов видно, что улучшение бейзлайна оказало положительное влияние на все модели, однако степень этого влияния различается. Наиболее впечатляющий прирост наблюдается у кастомных моделей — как у сверточной (CNN), так и у трансформерной. Изначально они демонстрировали относительно скромные показатели (в районе 40–45% точности на тесте), однако после улучшения уверенно преодолели порог в 60%, а трансформерная модель и вовсе приблизилась к 63%. Это говорит о том, что изначальная настройка бейзлайна значительно сдерживала потенциал архитектуры, и после внесения изменений (возможно, улучшение аугментаций, оптимизации, регулирований или структуры данных) модели смогли раскрыться гораздо полнее.

Более зрелые и мощные архитектуры, такие как VGG16 и ViT-B/16, показали высокие результаты уже до улучшений, но всё равно выиграли от оптимизаций. У VGG16 рост составил около 4.6% в точности на тесте, а у ViT прирост оказался менее выраженным, что может свидетельствовать о близости изначального состояния к оптимальному для этой модели. Тем не менее, ViT всё равно оказался лидером среди всех моделей по абсолютным значениям метрик, демонстрируя максимальную стабильность и общую сбалансированность результатов.

Таким образом, можно заключить, что улучшения бейзлайна были особенно критичны для кастомных моделей, позволив им выйти на уровень качества, сравнимый с промышленными решениями. Для предобученных моделей эти улучшения сыграли скорее роль дополнительной доводки, а не ключевого фактора успеха, однако даже в этом случае они обеспечили ощутимый прирост.

## Выводы по лабораторной работе №7

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

В ходе экспериментов сравнивались библиотечные и кастомные реализации CNN и трансформеров для задачи семантической сегментации до и после улучшения бейзлайна.

| Модель                      | IoU      | Dice   | Precision | Recall | 
|:---------------------------:|:--------:|:------:|:---------:|:------:|
| CNN (before)                | 0.5595   | 0.7124 | 0.6886    | 0.7504 |
| CNN (after)                 | 0.6754   | 0.8054 | 0.8047    | 0.8071 |
| Transformer (before)        | 0.6838   | 0.6838 | 0.8529    | 0.7735 |
| Transformer (after)         | 0.6921   | 0.8176 | 0.8647    | 0.7757 |
| Custom CNN (before)         | 0.7445   | 0.7445 | 0.96      | 0.4492 |
| Custom CNN (after)          | 0.732    | 0.7865 | 0.9617    | 0.4641 |
| Custom Transformer (before) | 0.6785   | 0.6785 | 0.8582    | 0.3198 |
| Custom Transformer (after)  | 0.7233   | 0.7173 | 0.942     |	0.4232 |

После доработки бейзлайна все модели показали рост метрик качества. Наилучшие значения IoU достигли кастомные модели: 
* Custom CNN — 0.732
* Custom Transformer — 0.7233

Также кастомные модели показали высокие значения Precision (до 0.96), подтверждая точность предсказаний.

Библиотечные модели при этом демонстрировали более сбалансированные метрики по Recall и Dice, особенно в трансформере.

Таким образом, улучшение бейзлайна положительно сказалось на всех моделях, а кастомные решения оказались конкурентоспособными и в ряде случаев — лидирующими.

## Выводы по лабораторной работе №8

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

| Модель          | Precision | Recall | Confusion matrix | mAP   | 
|:---------------:|:---------:|:------:|:----------------:|:-----:|
| YOLOv11         | 1.0       | 1.0    | ideal            | 0.995 |
| YOLOv8          | 1.0       | 1.0    | ideal            | 0.995 |
| Custom          | 0.9794    | 0.9831 | small errors     | 0.0   |
| Improved Custom | 1.0       | 1.0    | ideal            | 0.485 |

На основе полученных результатов лабораторной работы можно сделать следующие выводы относительно производительности различных моделей для задачи обнаружения объектов:

1. YOLOv11 и YOLOv8:
  * Оба варианта YOLOv11 и YOLOv8 продемонстрировали идеальные результаты с Precision и Recall, равными 1.0000, что свидетельствует о том, что модели правильно классифицировали все объекты без ложных срабатываний.
  * Матрица ошибок для обеих моделей является идеальной, что подтверждает отсутствие ошибок классификации.
  * mAP этих моделей составил 0.995, что подтверждает высокую производительность как в задаче классификации, так и в задаче локализации объектов.
2. Custom модель:
  * Custom модель показала Precision = 0.9794 и Recall = 0.9831, что указывает на то, что модель достаточно хорошо справляется с задачей классификации и локализации объектов, но при этом имеет некоторые ошибки, что привело к небольшому снижению показателей по сравнению с YOLO моделями.
  * Матрица ошибок свидетельствует о наличии небольших ошибок, особенно в части локализации объектов.
  * mAP для этой модели составил 0.000, что указывает на проблемы с локализацией объектов, несмотря на хорошие результаты в классификации.
3. Improved Custom модель:
  * Improved Custom модель была улучшена для повышения результатов обучения, и это отразилось на Precision и Recall, которые теперь составляют 1.0000, что говорит о идеальных значениях в классификации объектов.
  * Матрица ошибок также является идеальной, что подтверждает, что модель теперь классифицирует все объекты правильно, без ошибок.
  * Важным улучшением является то, что mAP для улучшенной модели составил 0.485, что значительно выше, чем у Custom модели. Это говорит о том, что улучшения в обучении также положительно сказались на локализации объектов, несмотря на оставшиеся сложности.
    
**Резюме:**

YOLOv11 и YOLOv8 продемонстрировали наилучшие результаты во всех аспектах: точность классификации и локализации практически идеальна, а mAP близка к максимальному значению.

Custom модель показала хорошие результаты в классификации, но проблемы с локализацией привели к mAP = 0.000, что является значительным ограничением.

Improved Custom модель продемонстрировала значительное улучшение: Precision и Recall = 1.0000, а также увеличение mAP до 0.485, что указывает на улучшение локализации объектов по сравнению с Custom моделью.
