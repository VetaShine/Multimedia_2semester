# Multimedia_2semester

**Студент: Минеева Светлана Алексеевна**

**Группа: М8О-410Б-21**

## Выводы по лабораторной работе №6

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

| Модель                      | Accuracy | F1     | Precision | Recall | 
|:---------------------------:|:--------:|:------:|:---------:|:------:|
| VGG16 (before)              | 0.6833   | 0.6827 | 0.688     | 0.6833 |
| VGG16 (after)               | 0.8293   | 0.8297 | 0.8308    | 0.8293 |
| ViT-B/16 (before)           | 0.242    | 0.2283 | 0.2405    | 0.242  |
| ViT-B/16 (after)            | 0.8233   | 0.8234 | 0.8267    | 0.8233 |
| Custom CNN (before)         | 0.6153   | 0.6139 | 0.6168    | 0.6153 |
| Custom CNN (after)          | 0.6233   | 0.6209 | 0.6239    | 0.6233 |
| Custom Transformer (before) | 0.436    | 0.4324 | 0.4524    | 0.436  |
| Custom Transformer (after)  | 0.6267   | 0.6222 | 0.6245    |	0.6267 |

После анализа представленных результатов видно, что улучшение бейзлайна оказало положительное влияние на все модели, однако степень этого влияния различается. Наиболее впечатляющий прирост наблюдается у кастомных моделей — как у сверточной (CNN), так и у трансформерной. Изначально они демонстрировали относительно скромные показатели (в районе 40–45% точности на тесте), однако после улучшения уверенно преодолели порог в 60%, а трансформерная модель и вовсе приблизилась к 63%. Это говорит о том, что изначальная настройка бейзлайна значительно сдерживала потенциал архитектуры, и после внесения изменений (возможно, улучшение аугментаций, оптимизации, регулирований или структуры данных) модели смогли раскрыться гораздо полнее.

Более зрелые и мощные архитектуры, такие как VGG16 и ViT-B/16, показали высокие результаты уже до улучшений, но всё равно выиграли от оптимизаций. У VGG16 рост составил около 4.6% в точности на тесте, а у ViT прирост оказался менее выраженным, что может свидетельствовать о близости изначального состояния к оптимальному для этой модели. Тем не менее, ViT всё равно оказался лидером среди всех моделей по абсолютным значениям метрик, демонстрируя максимальную стабильность и общую сбалансированность результатов.

Таким образом, можно заключить, что улучшения бейзлайна были особенно критичны для кастомных моделей, позволив им выйти на уровень качества, сравнимый с промышленными решениями. Для предобученных моделей эти улучшения сыграли скорее роль дополнительной доводки, а не ключевого фактора успеха, однако даже в этом случае они обеспечили ощутимый прирост.

## Выводы по лабораторной работе №7

Проанализируем результаты, полученные всеми алгоритмами. Для этого представим все данные в виде таблицы для удобства анализа.

В ходе экспериментов сравнивались библиотечные и кастомные реализации CNN и трансформеров для задачи семантической сегментации до и после улучшения бейзлайна.

| Модель                      | IoU      | Dice   | Precision | Recall | 
|:---------------------------:|:--------:|:------:|:---------:|:------:|
| CNN (before)                | 0.5595   | 0.7124 | 0.6886    | 0.7504 |
| CNN (after)                 | 0.6754   | 0.8054 | 0.8047    | 0.8071 |
| Transformer (before)        | 0.6838   | 0.6838 | 0.8529    | 0.7735 |
| Transformer (after)         | 0.6921   | 0.8176 | 0.8647    | 0.7757 |
| Custom CNN (before)         | 0.7445   | 0.7445 | 0.96      | 0.4492 |
| Custom CNN (after)          | 0.732    | 0.7865 | 0.9617    | 0.4641 |
| Custom Transformer (before) | 0.6785   | 0.6785 | 0.8582    | 0.3198 |
| Custom Transformer (after)  | 0.7233   | 0.7173 | 0.942     |	0.4232 |

После доработки бейзлайна все модели показали рост метрик качества. Наилучшие значения IoU достигли кастомные модели: 
* Custom CNN — 0.732
* Custom Transformer — 0.7233

Также кастомные модели показали высокие значения Precision (до 0.96), подтверждая точность предсказаний.

Библиотечные модели при этом демонстрировали более сбалансированные метрики по Recall и Dice, особенно в трансформере.

Таким образом, улучшение бейзлайна положительно сказалось на всех моделях, а кастомные решения оказались конкурентоспособными и в ряде случаев — лидирующими.

## Выводы по лабораторной работе №8
